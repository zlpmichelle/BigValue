# define mode
dataload.mode=mapred
dataload.source.streaming.fetch=false
buildIndex=true
# if there is one and only one larger file(larger than HDFS block size), set dataload.only.a.large.file to true. By default it is false.
dataload.only.a.large.file=true

# define data source
dataload.source.dataSourceClass=com.cloudera.bigdata.analysis.dataload.source.HDFSDataSource
#dataload.source.hdfsDirs=hdfs://vt-nn:8020/gd10g
dataload.source.hdfsDirs=hdfs://vt-nn:8020/asb2g

# define data format
dataload.source.parserType=csv
dataload.source.instanceDocPath=../conf/asbHdfs2hbase.xml

# define client for mapper
dataload.client.queueLength=40000
dataload.client.fetchParallel=60
dataload.client.threadsPerMapper=10

# define target table
hbase.target.table.name=test
indexConfFileName=test_index-conf.xml
server.search.enableStatistics=false
useHashUUIDForRowkey=true
regionQuantity=60
hbaseCoprocessorLocation=hdfs://vt-nn:8020/user/asb/BigValue-1.0.jar
hbase.table.useInMemory=

#hbase.table.splitKeyPrefixes=16163001,16163009,16163026,16163027,16163030,16163089,16163098,16163118,16163182
hbase.table.splitSize=100
hbase.table.writeToWAL=false
hbase.table.writeBufferSize=6
hbase.table.autoFlush=false
hbase.table.columnReplication=1
hbase.table.memStore=64

